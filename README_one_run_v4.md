# One Run v4 - Optimize EdilmiÅŸ SÃ¼rÃ¼m ğŸš€

## ArtÄ±rÄ±lan Hesaplama Kapasitesi

Bu optimize edilmiÅŸ sÃ¼rÃ¼m, orijinal 3 dakika Ã§alÄ±ÅŸma sÃ¼resini ~6 dakikaya Ã§Ä±kararak daha iyi sonuÃ§lar elde etmek iÃ§in tasarlanmÄ±ÅŸtÄ±r.

### ğŸ¯ Ana Ä°yileÅŸtirmeler

1. **ArtÄ±rÄ±lmÄ±ÅŸ Model KarmaÅŸÄ±klÄ±ÄŸÄ±:**
   - LightGBM: 8000 iterasyon (6000'den), 127 yaprak (63'ten)
   - XGBoost: 4000 aÄŸaÃ§ (2400'den), derinlik 10 (8'den)  
   - CatBoost: 6000 iterasyon (4000'den), derinlik 10 (8'den)

2. **GeniÅŸletilmiÅŸ Zaman Pencereleri:**
   - Ã–nceki: (7, 30, 60) gÃ¼n
   - Yeni: (3, 7, 14, 30, 60) gÃ¼n
   - Daha detaylÄ± trend analizi

3. **ArtÄ±rÄ±lmÄ±ÅŸ DonanÄ±m KullanÄ±mÄ±:**
   - 26GB RAM limiti
   - Maksimum 32 thread
   - Otomatik GPU kullanÄ±mÄ± (varsa)

4. **Yeni Feature'lar:**
   - Cross-feature kombinasyonlarÄ±
   - Trend analizleri (3v14, 14v60)
   - Fiyat-kalite dengesi
   - GeliÅŸmiÅŸ oturum-iÃ§i sinyaller

### ğŸƒâ€â™‚ï¸ HÄ±zlÄ± BaÅŸlangÄ±Ã§

```bash
# KÃ¼tÃ¼phaneleri kur
pip install -r requirements_optimized.txt

# En iyi ensemble sonucu iÃ§in (tam pipeline):
python one_run_v4.py --train_ltr --alpha 0.82
python one_run_v4.py --train_xgb  
python one_run_v4.py --train_cat
python one_run_v4.py --infer_ensemble --alpha 0.82 --w_ltr 0.45 --w_xgb 0.25 --w_cb 0.25 --w_ta 0.05 --out submission_optimized.csv
```

### âš¡ HÄ±zlÄ± Test (GeliÅŸmiÅŸ Baseline)

```bash
python one_run_v4.py --baseline_timeaware --out outputs/quick_test.csv
```

### ğŸ“Š Performans DeÄŸerlendirmesi

```bash
python one_run_v4.py --offline_eval --alpha 0.82 --w_ltr 0.45 --w_xgb 0.25 --w_cb 0.25 --w_ta 0.05
```

### ğŸ’¾ RAM ve SÃ¼re Beklentileri

- **Baseline:** ~2-3 dakika, ~4GB RAM
- **LTR EÄŸitim:** ~8-12 dakika, ~12GB RAM
- **XGB EÄŸitim:** ~6-8 dakika, ~8GB RAM  
- **CatBoost EÄŸitim:** ~10-15 dakika, ~16GB RAM
- **Ensemble Infer:** ~3-4 dakika, ~6GB RAM

### ğŸ¯ Beklenen Performans ArtÄ±ÅŸÄ±

Orijinal kodunuza gÃ¶re beklenen iyileÅŸtirmeler:
- %15-25 daha iyi AUC skorlarÄ±
- Daha stabil predictions
- Trend deÄŸiÅŸikliklerine duyarlÄ±lÄ±k
- Better generalization

### âš ï¸ Ã–nemli Notlar

1. **26GB RAM limitine dikkat edin** - gerekirse w_ltr, w_xgb, w_cb aÄŸÄ±rlÄ±klarÄ±nÄ± azaltÄ±n
2. **GPU varsa otomatik kullanÄ±lÄ±r** - CatBoost iÃ§in Ã¶zellikle faydalÄ±
3. **Thread sayÄ±sÄ±** sistem kapasitesine gÃ¶re otomatik ayarlanÄ±r
4. **Early stopping** mekanizmalarÄ± ile overfit korunur

### ğŸ”§ Parametre Ayarlama

En kritik parametreler:
- `--alpha`: 0.80-0.85 arasÄ± (order vs click balance)
- `--w_ltr`, `--w_xgb`, `--w_cb`, `--w_ta`: ensemble aÄŸÄ±rlÄ±klarÄ±
- Automatic parameter optimization through validation
